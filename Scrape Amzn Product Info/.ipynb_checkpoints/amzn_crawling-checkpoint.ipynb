{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return web link based on searching result, like searching for jacket\n",
    "def get_page_url(key_words, page_num, proxy):\n",
    "    search_key_words = 'http://www.amazon.com/s?url=search-alias%3Daps&field-keywords='\n",
    "    return search_key_words + key_words + '&page=' + str(page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a product's link page and returns the attributes of the product in a dictionary, including product name, category and price\n",
    "def product_parser(url):\n",
    "    # read a url page\n",
    "    page = requests.get(url)\n",
    "    tree = html.fromstring(page.content)\n",
    "\n",
    "    # match the tags to find product attributes \n",
    "    name = tree.xpath('//h1[@id=\"title\"]//text()')\n",
    "    sale_price = tree.xpath('//span[contains(@id,\"ourprice\") or contains(@id,\"saleprice\")]/text()')\n",
    "    original_price = tree.xpath('//td[contains(text(),\"List Price\") or contains(text(),\"M.R.P\") or contains(text(),\"Price\")]/following-sibling::td/text()')\n",
    "    category = tree.xpath('//a[@class=\"a-link-normal a-color-tertiary\"]//text()')\n",
    "    availability = tree.xpath('//div[@id=\"availability\"]//text()')\n",
    "\n",
    "    # clean the results for each attribute\n",
    "    name = ' '.join(''.join(name).split()) if name else None\n",
    "    sale_price = float(''.join(sale_price).split()[0][1:]) if sale_price else None\n",
    "    category = ' > '.join([i.strip() for i in category]) if category else None\n",
    "    # original_price = float(''.join(sale_price).split()[0][1:]) if original_price else None\n",
    "    availability = ''.join(availability).strip() if availability else None\n",
    "    \n",
    "    if not original_price:\n",
    "        original_price = sale_price\n",
    "        \n",
    "    info = {\n",
    "        'Name':name,\n",
    "        'Sale price':sale_price,\n",
    "        'Category':category,\n",
    "        # 'Original price':original_price,\n",
    "        'Availability':availability,\n",
    "        #'URL':url,       \n",
    "    }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes a web page which lists different products in one page, and returns a list of ASIN numbers from the page\n",
    "def get_product_asin(page_url):\n",
    "    asin = []\n",
    "    soup = BeautifulSoup(requests.get(page_url).content)\n",
    "    for p in soup.findAll('li',{'data-asin': re.compile('.{8}') }):\n",
    "        asin.append(p['data-asin'])\n",
    "    return asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def page_parser(page_url):\n",
    "    if len(page_url) == 0:\n",
    "        return 'Empty URL'\n",
    "    asin = get_product_asin(page_url)\n",
    "    product_list = []\n",
    "    for i in asin:\n",
    "        # find a product web link based on its ASIN number\n",
    "        product_link = 'https://www.amazon.com/dp/' + i\n",
    "        # find the product's attributes based on the product link\n",
    "        product_list.append(product_parser(product_link))\n",
    "    return product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'B0058YHKDI',\n",
       " u'B0065Q0RL0',\n",
       " u'B00D7G6UXK',\n",
       " u'B01FFJN9GW',\n",
       " u'B072X91CJ3',\n",
       " u'B002MFW7D4',\n",
       " u'B01N3UENOB',\n",
       " u'B01N5V78VH',\n",
       " u'B00DQYWIHA',\n",
       " u'B0746CSC1H',\n",
       " u'B071X4CSSQ',\n",
       " u'B06XJ2699G',\n",
       " u'B00LEX0WRI',\n",
       " u'B06ZZ5676J',\n",
       " u'B008G4LKJ2',\n",
       " u'B06XDBSNJ1']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Case\n",
    "page_parser(get_page_url('jacket', 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [logit]",
   "language": "python",
   "name": "Python [logit]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
